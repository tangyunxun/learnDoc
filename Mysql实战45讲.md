#### 1.基础架构：一条SQL查询语句是如何执行的？

<img src="C:\Users\Axun\Desktop\mysql基本架构图.png" style="zoom: 25%;" />

连接器：建立连接

分析器：词法分析、语法分析。语法不对就会收到“You have an error in your SQL syntax”。

优化器：决定使用哪个索引，多表关联时的关联顺序等等。

执行器：先判断对表有没有操作权限，有的话则继续调用引擎的接口

查询缓存：多数情况下不建议使用。mysql8.0已经删掉了这个模块

判断表结构是否包含某字段，发生在**分析器**。



#### 2.日志系统：一条SQL更新语句是如何执行的？

redo log与binlog不同之处：

+ redo log是InnodDB特有，binlog属于server层；
+ redo log是物理日志，binlog 是逻辑日志；
+ redo log是循环写的，binlog追加写。

update语句执行流程：

<img src="C:\Users\Axun\Desktop\mysql更新流程.png" style="zoom:25%;" />

redo log与binlog的**二阶段提交**。

建议：innodb_flush_log_at_trx_commit设置成1，表示每次事务的redo log都持久化到磁盘；

sync_binlog也设置成1，表示每次事务的binlog都持久化到磁盘。



#### 3.事务隔离：为什么你改了我还看不见？

隔离级别：

+ 读未提交（脏读），当前读
+ 读已提交（不可重复读），使用每个语句执行前的read view
+ 可重复读（幻读），使用每个事务最初的read view
+ 串行化，加锁避免并行访问

可重复读的场景：对账。

每次更新都会同时记录一条undo log，当没有事务需要用到该undo log时，系统才会将之删除。

长事务的影响：undo log不能及时删除；锁长时间得不到释放，对于高并发的更新，连接容易被打满；主从同步延迟大。



#### 4-5.索引基础

索引常见模型：

+ 哈希表。适用于等值查询。
+ 数组。适用于等值查询以及范围查询，但是对增删数据不友好，**适用于静态存储**。
+ B+树。树高与磁盘访问次数成正比。尽量缩小key的长度，使得一个数据页存储更多的key，以缩小树高。主键尽量使用递增的id。

使用B+树作为索引的原因：**B+树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。**

回表：回到主键索引树搜索的过程，称为回表。

覆盖索引：索引中包含全部待查询字段，不需要回表，此时称为覆盖索引。（字符串的前缀索引会使得覆盖索引失效）

最左前缀。建立联合索引的时候，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往是需要优先考虑的。其次考虑占用空间。

索引下推：**在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。**

倒排索引：搜索引擎中的概念。把文章分词后的单词作为key，value存储与之对应的文档id以及其他信息。



#### 6.全局锁和表锁 ：给表加个字段怎么有这么多阻碍？

根据加锁的范围：全局锁、表级锁、行锁。

+ 加全局锁的典型场景：全库逻辑备份。InnoDB使用mysqldump;对于不支持事务的引擎，推荐FTWRL：整个库处于只读状态。

+ 表级锁：表锁、元数据锁（MDL）。

  当对数据库做DML时，加MDL读锁，做DDL时，加MDL写锁。

  事务中的MDL，在语句开始执行时申请，在事务提交后释放。

  热点表，加个字段真的挺难。kill长事务；在alter table语句中加入等待时间，能够在指定时间内拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。



#### 7.行锁功过：怎么减少行锁对性能的影响？

两阶段锁协议：InnoDB中，行锁在需要的时候加上，事务提交后才释放。

因此，我们要把最可能造成锁冲突、最可能影响并发的的锁尽量往后放。

处理死锁策略，往往采用死锁检测：

1. 直接进入等待，直到超时。通过参数 innodb_lock_wait_timeout 根据实际业务场景来设置超时时间，InnoDB引擎默认值是50s。
2. 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务。innodb_deadlock_detect 设置为 on，表示开启这个逻辑（默认是开启状态）

死锁检测：每个新来的被堵住的线程，都要判断会不会由于自己的加入导致死锁，这是一个O(n)的操作。

热点行的更新，死锁检测效率较低，应对方案：

1. 如果业务可以确保无死锁，那么可以关掉死锁检测。（不推荐）
2. 控制并发度，限流。对应相同行的更新，在进入引擎之前排队。
3. 将热更新的行数据拆分成逻辑上的多行来减少锁冲突，但是业务复杂度可能会大大提高。

**innodb行级锁是通过锁索引记录实现的，如果更新的列没建索引是会锁住整个表的。**



#### 8.事务到底是隔离的还是不隔离的？

InnoDB为每一个事务构造一个数组，用来保存在事务启动的瞬间，当前正在活跃（启动了但还没提交）的所有事务ID。

事务ID的最小值记为低水位，**当前系统里面已经创建过的事务ID的最大值加1记为高水位**。这个视图数组和高水位就构成了当前事务的一致性读视图。InnoDB利用了“所有数据都有多个版本”的特性，实现了“**秒级创建快照**”的能力。

<img src="C:\Users\Axun\Desktop\mysql数据版本可见性规则.png" style="zoom: 33%;" />

1. 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；

2. 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；

3. 如果落在黄色部分，那就包括两种情况

   a.  若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；

   b.  若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。

更新语句都是先读后写的，这个读只能读当前值，称为“**当前读**”（current read）。



#### 9.普通索引和唯一索引，应该怎么选择？

两方面考虑：

+ 对于查询语句，唯一索引效率稍高，但是可以忽略不计。

+ 对于更新操作，唯一索引不能使用change buffer。

change buffer适用于写多读少，不适用于写了立即读的场景，那样反而会成为累赘。

**redo log主要减少随机写磁盘，change buffer主要减少随机读磁盘。**

仔细体会更新的细节，忘记就回去看原文。

系统突然宕机，change buffer数据丢失，会使得更新丢失吗？

不会，因为redo log记录了change buffer的值，崩溃恢复的时候能找回来。



#### 10.MySQL为什么有时候会选错索引？

判断依据：扫描行数、是否使用临时表、是否需要排序

+ force index强行选择一个索引
+ 修改语句，引导mysql使用我们期望的索引
+ 有些场景下，新建一个更合适的索引或删掉误用的索引

感觉本文不是太重要。

全文不太重要

#### 11. 怎么给字符串字段加索引？

字符串字段创建索引的场景:

+ 直接创建完整索引，这样可能比较占用空间；
+ 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；
+ 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；
+ 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。

在实际应用中，你要根据业务字段的特点选择使用哪种方式。



#### 12.为什么我的MySQL会“抖”一下？

刷脏页（flush）会导致查询或更新慢一些。刷脏页的四种场景：

+ redo log满了。这时候会停止所有更新操作
+ 内存没有空闲page cache，需要淘汰一些（LRU），如果是脏页就要flush
+ 空闲的时候flush脏页
+ mysql正常关闭的时候flush

刷脏页虽然是常态，但是出现以下两种情况，都是会明显影响性能的：

+ 一个查询要淘汰的脏页太多，导致查询时间明显增长
+ redo log写满，更新全部堵住，写性能跌为0，这种情况对敏感业务来说是不能接受的。

innodb_max_dirty_pages_pct 指定脏页比例上限

刷脏页的连坐机制 innodb_flush_neighbors。机械硬盘有用，减少随机写。ssd建议取消。

#### 13.为什么表数据删掉一半，表文件大小不变？

造成数据空洞的情况：

+ delete命令只是把记录的位置或者数据页标记为“可复用”，但磁盘文件的大小是不会变的。

+ 随机插入数据，可能会造成页分裂，从而造成空洞；

+ 更新索引的值，可以理解为删除旧值，插入新值，也会造成空洞

经过大量增删改查的表都是存在空洞的。重建表可以把这些空洞去掉。

重建表的细节暂不关心。



#### 14.count(*)这么慢，我该怎么办？

count(*)的实现方式：

+ 在MyISAM中，存储了全表的总行数，可以直接返回，效率很高。
+ InnoDB中，没有存储总行数（因为mvcc的存在）， 需要把数据一行行地从引擎中读出来，效率不高。

使用缓存（redis）存储总行数，缺陷是即使缓存不出问题，那么写缓存和写数据库之间的时间差，也难保逻辑正确。

把计数存在mysql的计数表里，和业务增删数据在一个事务中。

按照效率排序的话，count(字段)<count(主键 id)<count(1)≈count(\*)，所以尽量使用 count(*)。



#### 16.“order by”是怎么工作的？

max_length_for_sort_data，用于控制mysql中参与排序的行数据的长度的参数。如果单行超过这个值，就是用rowid排序。

全字段排序：所有查询的字段都放入sort buffer，排序完直接返回，不需要回表。

rowid排序：参与排序字段和主键id放入sort buffer，排序完拿着id回表查出待查询数据。

因为原来的数据是无序的，才需要排序。若是有序的，order by可以不排序，争取用到索引。



#### 17.如何正确地显示随机消息？

本节内容比较干，建议多看原文。

rowid的含义：

+ 对于有主键的 InnoDB 表来说，这个 rowid 就是主键 ID；
+ 对于没有主键的 InnoDB 表来说，这个 rowid 就是由系统生成的；
+ MEMORY 引擎不是索引组织表。在这个例子里面，你可以认为它就是一个数组。因此，这个 rowid 其实就是数组的下标。







#### 18.为什么这些SQL语句逻辑相同，性能却差异巨大？

B+树提供的快速定位能力，源自于同一层兄弟节点的有序性。

**对索引字段的函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。**但并不是放弃使用这个索引。

触发函数操作的场景：

+ 显示使用函数，x+1=10000也不行，应该写成x = 10000-1；
+ 隐式类型转换；
+ 隐式字符编码转换。



#### 19.为什么我只查一行的语句，也执行这么慢？

+ 查询长时间不返回
  - 等MDL锁（一个线程正在表t请求或者持有MDL写锁，把select语句堵住了）
  - 等flush（flush tables t with read lock; flush tables with read lock;正常这两个执行都很快，除非被别的线程堵住了）
  - 等行锁（select * from t where id=1 lock in share mode;如果一个事务已经在该行持有写锁，就会堵住该select）
+ 查询慢
  - 没用到索引，扫描行数多
  - 用到主键索引，扫描行数是1。长事务大量的执行undo log回退版本，也会很慢。





#### 20. 幻读是什么，幻读有什么问题？

幻读：是指一个事务中前后两次查询同一范围，后一次查询看到了前一次查询没看到的行。

幻读的说明：

+ 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读仅在“当前读”下才会出现；
+ 幻读仅指“新插入的行”。

幻读的问题：

+ 语义。
+ 数据一致性。

为了解决幻读而引入间隙锁。**跟间隙锁存在冲突关系的，是“往这个间隙中插入一行记录”这个操作**。

间隙锁和行锁合称next-key lock，每个next-key lock都是前开后闭区间。

间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。

间隙锁只有在可重复读隔离级别下才生效。



#### 21.为什么我只改一行的语句，锁这么多？

列举了8种加锁的例子，值得好好体会，多看看原文。

加锁规则：

1. 查询过程中访问到的对象才会加锁，而加锁的基本单位是next-key lock（前开后闭）；
2. 等值查询上MySQL的优化：索引上的等值查询，如果是唯一索引，next-key lock会退化为行锁，如果不是唯一索引，需要访问到第一个不满足条件的值，此时next-key lock会退化为间隙锁；
3. 范围查询：无论是否是唯一索引，范围查询都需要访问到不满足条件的第一个值为止；



#### 22.MySQL有哪些“饮鸩止渴”提高性能的方法？

没仔细看，不太吸引我。有时间在研究。

#### 23.MySQL是怎么保证数据不丢的？

这一篇文章很精彩，多看。

###### binlog的写入机制：

事务执行过程中，先把日志写到binlog cache中，事务提交的时候再把binlog cache写道磁盘中。

一个事务的binlog是不能被拆开的，因此不论这个事务有多大，也要确保一次性写入。每个线程使用binlog_cache_size控制线程内的	binlog cache内存大小。如果超过这个值，就要暂存到磁盘。

write和fsync的时机是由**sync_binlog**来控制的：

+ sync_binlog=0，每次事务提交都只write，不fsync。
+ sync_binlog=1，每次提交事务都会fsync。
+ sync_binlog=N（N>1），每次提交事务都write，但累积N个事务后才fsync。

<img src="C:\Users\Axun\Desktop\mysql_binlog.png" style="zoom: 50%;" />



###### redo log的写入机制：

InnoDB提供了**innodb_flush_log_at_trx_commit**参数，三种取值：

+ 0， 每次事务提交时都只是把redo log留在redo log buffer中；
+ 1， 每次事务提交时都将redo log直接持久化到磁盘；
+ 2，每次事务提交时都只是把redo log写到page cache。

WAL机制主要得益于两个方面：

+ redolog和binlog都是顺序写，磁盘的顺序写比随机写速度快很多；
+ 组提交机制，可以大幅度降低磁盘的IOPS消耗。

数据库的crash-safe只需要保证：

1. 如果客户端收到事务成功的消息，事务就一定持久化了；
2. 如果客户端收到事务失败的消息（比如主键冲突、回滚等），事务就一定失败了；
3. 如果客户端收到“执行异常”的消息，应用需要重连后通过查询当前状态来继续后续的逻辑。**此时数据库只需要保证内部**（数据和日志之间、主库和备库之间）一致就可以了。







#### 24.MySQL是怎么保证主备一致的？

###### binlog的三种格式

+ statement。忠实地记录sql原文，甚至连注释都带着。缺点：主备数据可能不一致，例如同一条sql主备用到不同的索引。
+ row。记录更新前后两行数据。缺点是：很占空间。现在越来越倾向于使用row格式，因为方便恢复数据。
+ mixed。MySQL自己会判断这条SQL是否会引起主备不一致，如果有可能就用row格式，否则就用statement格式。

###### 主备的循环赋值问题

1. 规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系；
2. 一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的 binlog；
3. 每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。

###### 几个有趣的问题

Q: 主库 A 从本地读取 binlog，发给从库 B。请问这里的本地是指文件系统的 page cache还是disk呢？

A: 是这样的，对于A的线程来说，就是“读文件”，

1. 如果这个文件现在还在 page cache中，那就最好了，直接读走；
2. 如果不在page cache里，就只好去磁盘读

这个行为是文件系统控制的，MySQL只是执行“读文件”这个操作



如果在同步的过程中修改了server id，那用原server id 生成的log被两个M认为都不是自己的而被循环执行，不知这种情况会不会发生?

会。



#### 25.MySQL是怎么保证高可用的？

###### 主备延迟

与数据同步有关的时间点主要包括以下三个：

1. 主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1;
2. 之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2;
3. 备库 B 执行完成这个事务，我们把这个时刻记为 T3。

所谓主备延迟，就是同一个事务，在备库执行完成的时间和在主库执行完成的时间差值，也就是T3-T1。

在备库执行show slave status命令，可以看到seconds_behind_master，用于表示当前备库延迟了多少秒。

seconds_behind_master其实就是T3-T1，它的计算方法是：

1. 每个事务的binlog里记录了主库写入的时间；
2. 备库取出当前正在执行的事务的时间字段的值，计算它与系统当前时间的差值，得到seconds_behind_master。

主库备库的系统时间不一致也不会影响这个计算，因为会自动扣掉系统时间差值。

正常情况下，T2-T1时间是很短的，主备延迟主要来自于T3-T2。

###### 主备延迟的来源

+ 备库所在机器硬件比主库所在机器差；
+ 备库的读压力大；
  - 一主多从，分担读压力
  - 通过binlog输出到外部系统，让外部系统提供统计类查询的功能
+ 大事务；
  - 不要一次删除大量数据
  - 大表DDL
+ 备库的并行复制能力；

###### 主备切换的两种策略

可靠性优先策略

可用性优先策略

主备切换的可用性优先策略会导致数据不一致。因此，大多数情况下，我都建议你使用可靠性优先策略。毕竟对数据服务来说的话，数据的可靠性一般还是要优于可用性的。



#### 26.备库为什么会延迟好几个小时？

详细介绍了几种并行复制策略，不熟悉这块内容，有时间看原文吧。



#### 27.主库出问题了，从库怎么办？



#### 33.我查这么多数据，会不会把数据库内存打爆？

###### 全表扫描对server层的影响

服务端并不需要保存一个完整的结果集，而是**边读边发**。取数据和发数据的流程是这样的：

1. 获取一行，写到 net_buffer 中。这块内存的大小是由参数 net_buffer_length 定义的，默认是 16k。
2. 重复获取行，直到 net_buffer 写满，调用网络接口发出去。
3. 如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。
4. 如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送。

**查询的结果是分段发给客户端的，因此扫描全表，查询大量数据不会把内存打爆。**

<img src="C:\Users\Axun\Desktop\mysql查询结果发送流程.jpg" style="zoom: 50%;" />

###### 全表扫描对InnoDB的影响

InnoDB采用改进版的LRU算法管理Buffer Pool ：

在 InnoDB 实现上，按照 5:3 的比例把整个 LRU 链表分成了 young 区域和 old 区域。图中 LRU_old 指向的就是 old 区域的第一个位置，是整个链表的 5/8 处。也就是说，靠近链表头部的 5/8 是 young 区域，靠近链表尾部的 3/8 是 old 区域。

1. 图 7 中状态 1，要访问数据页 P3，由于 P3 在 young 区域，因此和优化前的 LRU 算法一样，将其移到链表头部，变成状态 2。
2. 之后要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页 Pm，但是新插入的数据页 Px，是放在 LRU_old 处。
3. 处于 old 区域的数据页，每次被访问的时候都要做下面这个判断：
   + 若这个数据页在 LRU 链表中存在的时间超过了 1 秒，就把它移动到链表头部；
   + 如果这个数据页在 LRU 链表中存在的时间短于 1 秒，位置保持不变。1 秒这个时间，是由参数 innodb_old_blocks_time 控制的。其默认值是 1000，单位毫秒。

对于全表扫描：

1. 扫描过程中，需要新插入的数据页，都被放到 old 区域 ;
2. 一个数据页里面有多条记录，这个数据页会被多次访问到，但由于是**顺序扫描**，这个数据页第一次被访问和最后一次被访问的时间间隔不会超过 1 秒，因此还是会被保留在 old 区域；
3. 再继续扫描后续的数据，之前的这个数据页之后也不会再被访问到，于是始终没有机会移到链表头部（也就是 young 区域），很快就会被淘汰出去。

<img src="C:\Users\Axun\Desktop\mysql改进的LRU算法.png" style="zoom: 50%;" />





#### 34.到底可不可以使用join？

###### 三种Join算法

假设驱动表上的行数是N，被驱动表行数是M。

+ Index Nested-Loop  Join

  被驱动表能使用上索引。整个执行过程的近似复杂度：
  $$
  N + N*2*log_2M
  $$
  可以看出N对复杂度影响更大，应该让小表作为驱动表。

+ Simple Nested-Loop Join

  两个表都用不到索引，总扫描行数是M*N。MySQL并没有使用该算法。

+ Block Nested-Loop Join

  被驱动表用不到索引。

  1. 把表 t1 的数据读入线程内存 join_buffer 中，由于我们这个语句中写的是 select *，因此是把整个表 t1 放入了内存；
  2. 扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。

###### 两个问题

能不能用Join语句？

1. 如果可以使用 Index Nested-Loop Join 算法，也就是说可以用上被驱动表上的索引，其实是没问题的；
2. 如果使用 Block Nested-Loop Join 算法，扫描行数就会过多。尤其是在大表上的 join 操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种 join 尽量不要用。

如果要使用 join，应该选择大表做驱动表还是选择小表做驱动表？

1. 如果是 Index Nested-Loop Join 算法，应该选择小表做驱动表；

2. 如果是 Block Nested-Loop Join 算法：

   - 在 join_buffer_size 足够大的时候，是一样的；

   - 在 join_buffer_size 不够大的时候（这种情况更常见），应该选择小表做驱动表。

     所以，这个问题的结论就是，**总是应该使用小表做驱动表**。

**在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。**





#### 35.join语句怎么优化？

+ Multi-Range Read(MRR)
+ Batched Key Access(BKA)



#### 38.都说InnoDB好，那还要不要使用Memory引擎？



#### 45.自增id用完怎么办？

+ **表定义自增id**。达到上限后，申请下一个id时，得到的值保持不变。
+ **InnoDB系统自增row_id**。达到上限后，下一个值就是0，然后继续循环。插入0不会报主键冲突，而是覆盖那一行数据。
+ **Xid**。取自global_query_id，8字节，该值存在于内存中，重启。达到上限后从0开始计数，这样一个binlog文件中就可能会出现两个相同的Xid。但是2^64-1，这个数字太大了，达到上限的可能仅存在于理论上。
+ **InnoDB trx_id**。Xid是由Server层维护的。InnoDB内部使用Xid，就是为了能够在InnoDB事务和Server之间做关联。但是InnoDB自己的trx_id，是另外维护的。InnoDB内部维护一个max_trx_id全局变量，每次需要申请一个新的trx_id时，取max_trx_id+1。max_trx_id持久化存储，因此总会增加到上限。
+ **thread_id**。系统保存了一个全局变量 thread_id_counter，每新建一个连接，就将 thread_id_counter 赋值给这个新连接的线程变量。大小是 4 个字节，因此达到 232-1 后，它就会重置为 0。但是，你不会在 show processlist 里看到两个相同的 thread_id。
